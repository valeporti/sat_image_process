{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import subprocess\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_sortie = './output/'\n",
    "dir_SUMO = '/home/valeporti/Documents/SUMO'\n",
    "dir_images = '../peps_download/'\n",
    "dir_unzip = './imageUnzip/'\n",
    "dir_history = './history.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runSumo(image_dir, sumo_dir, output_dir):\n",
    "\n",
    "    thh = tvv = 1.5\n",
    "    thv = tvh = 1.2\n",
    "    \n",
    "    if not os.path.exists(output_dir + '/'): os.makedirs(output_dir + '/')\n",
    "\n",
    "    if (not os.path.isdir(sumo_dir) or not os.path.exists(image_dir) or not os.path.isdir(output_dir)) :\n",
    "        print('error, directory does not exist')\n",
    "        print(os.path.isdir(sumo_dir))\n",
    "        print(os.path.exists(image_dir))\n",
    "        print(os.path.isdir(output_dir))\n",
    "        return \n",
    "    \n",
    "    s1_file = image_dir + '/manifest.safe'\n",
    "    subprocess.check_call(f'cd {sumo_dir}/ && {sumo_dir}/start_batch.sh -i {image_dir} -thh {thh} -thv {thv} -tvh {tvh} -tvv {tvv} -sh {sumo_dir}/resources/coastline/OSMLandPoly_20141001_250/OSMLandPoly_20141001_250m.shp -b 0 -o {output_dir}',\n",
    "        shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addElementToListInPickle(dir_file, element, to_add = True):\n",
    "    list_pickle = []\n",
    "    if not os.path.exists(dir_file): \n",
    "        with open(dir_file, 'wb') as f:\n",
    "            pickle.dump([], f)\n",
    "            \n",
    "    with open (dir_file, 'rb') as fp:\n",
    "        list_pickle = pickle.load(fp)\n",
    "        \n",
    "    if to_add and element not in list_pickle:\n",
    "        with open (dir_file, 'wb') as fp:\n",
    "            list_pickle.append(element)\n",
    "            pickle.dump(list_pickle, fp)\n",
    "            \n",
    "    return list_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S1A_IW_GRDH_1SDV_20151108T214317_20151108T214342_008519_00C0F6_1D0E', 'S1A_IW_GRDH_1SDV_20151113T060026_20151113T060051_008582_00C2BD_DC5F', 'S1A_IW_GRDH_1SDV_20190404T091203_20190404T091232_026638_02FD17_0761', 'S1A_IW_GRDH_1SDV_20151108T214317_20151108T214342_008519_00C0F6_1D0E', 'S1A_IW_GRDH_1SDV_20151113T060026_20151113T060051_008582_00C2BD_DC5F', 'S1A_IW_GRDH_1SDV_20190404T091203_20190404T091232_026638_02FD17_0761']\n",
      "['S1A_IW_GRDH_1SDV_20151108T214317_20151108T214342_008519_00C0F6_1D0E', 'S1A_IW_GRDH_1SDV_20151113T060026_20151113T060051_008582_00C2BD_DC5F', 'S1A_IW_GRDH_1SDV_20190404T091203_20190404T091232_026638_02FD17_0761', 'S1A_IW_GRDH_1SDV_20151108T214317_20151108T214342_008519_00C0F6_1D0E', 'S1A_IW_GRDH_1SDV_20151113T060026_20151113T060051_008582_00C2BD_DC5F', 'S1A_IW_GRDH_1SDV_20190404T091203_20190404T091232_026638_02FD17_0761']\n",
      "['S1A_IW_GRDH_1SDV_20151108T214317_20151108T214342_008519_00C0F6_1D0E', 'S1A_IW_GRDH_1SDV_20151113T060026_20151113T060051_008582_00C2BD_DC5F', 'S1A_IW_GRDH_1SDV_20190404T091203_20190404T091232_026638_02FD17_0761', 'S1A_IW_GRDH_1SDV_20151108T214317_20151108T214342_008519_00C0F6_1D0E', 'S1A_IW_GRDH_1SDV_20151113T060026_20151113T060051_008582_00C2BD_DC5F', 'S1A_IW_GRDH_1SDV_20190404T091203_20190404T091232_026638_02FD17_0761']\n"
     ]
    }
   ],
   "source": [
    "# get Zip\n",
    "# Unzip\n",
    "# treat\n",
    "# OutputImages\n",
    "if not os.path.exists(dir_unzip): os.makedirs(dir_unzip)\n",
    "list_files = os.listdir(dir_images)\n",
    "list_files_unziped = [n.split('.')[0] for n in os.listdir(dir_unzip)]\n",
    "count = 0\n",
    "for file_name in list_files:\n",
    "    file_name_arr = file_name.split('_')\n",
    "    if 'S1' in file_name_arr[0] and '.zip' in file_name_arr[-1] and 'GRD' in file_name_arr[2]: # S1 image zip\n",
    "        image_name = file_name.split('.')[0]\n",
    "        if not image_name in list_files_unziped:\n",
    "            #zip_ref = zipfile.ZipFile(dir_images + file_name, 'r')\n",
    "            #zip_ref.extractall(dir_unzip)\n",
    "            #zip_ref.close()\n",
    "            \n",
    "            #print(addElementToListInPickle(dir_history, image_name, False))\n",
    "            \n",
    "       # if not image_name in \n",
    "            count += 1\n",
    "        \n",
    "        #runSumo(dir_unzip + image_name + '.SAFE', dir_SUMO, dir_sortie + image_name + '/')\n",
    "        \n",
    "    if count > 2 : break\n",
    "\n",
    "# once ended for all images\n",
    "# obtain in a list all dates of downloader\n",
    "\n",
    "# for each detection in the AIS, comparer si c'est +- 1h de difference et voir s'il y a une détection près de\n",
    "# il faut établir une distance??\n",
    "\n",
    "# dire si c'est ou pas\n",
    "\n",
    "# il va falloir de quelque manière indexer les images pour les passer au résau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
